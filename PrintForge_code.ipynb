{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6057,"status":"ok","timestamp":1732365997423,"user":{"displayName":"Smit Patel","userId":"15656836137006350723"},"user_tz":-330},"id":"_UDsnAUfruEv","outputId":"ca338ea6-b74c-4a33-e75a-fc9a8fce1aa2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"]}],"source":["!pip install numpy matplotlib\n","!pip install torch torchvision\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2563,"status":"ok","timestamp":1732366874465,"user":{"displayName":"Smit Patel","userId":"15656836137006350723"},"user_tz":-330},"id":"lEPwU8NtHJ-L","outputId":"417e03ab-4bdd-44cc-ddc4-b1348533ffa0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"]}],"source":["pip install tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VfrQ8ft7HkLA"},"outputs":[],"source":["!unzip /content/FingerGAN-master.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1fTPNQnFrS4O3WyRm1HDCrP0jZ8D6Amfw"},"id":"THs7_maaLC50","outputId":"3b15836c-67e3-4e30-816b-5c08d2d31de0"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import argparse\n","import os\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","from tqdm import tqdm\n","\n","SEED = 1234\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","# path to training images\n","dataroot = \"/content/FingerGAN-master/data\"\n","\n","# training batch size\n","batch_size = 128\n","\n","# image dimension pixels\n","image_size = 64\n","\n","# color channels\n","nc = 3\n","\n","# latent vector size for generator input\n","nz = 100\n","\n","# feature size generator\n","ngf = 64\n","\n","# feature size discriminator\n","ndf = 64\n","\n","# training runs (\"epochs\")\n","num_epochs = 50\n","\n","# learning rate, from paper\n","lr = 0.0002\n","\n","# param for Adam optimizer\n","beta1 = 0.5\n","\n","# initializes weights per DCGAN paper\n","def init_weights(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)\n","\n","class Generator(nn.Module):\n","    \"\"\"\n","    Helper class for the generator module\n","\n","    We have four convolutional stages, with normalizations between each\n","    Individual kernels are 4x4, with other dimensions/strides scaled\n","    accordingly.\n","\n","    The rectified linear activation function ReLU allows fast training while\n","    avoiding problems associated with sigmoids, etc (vanishing gradients)\n","    The final application of tanh maps the output to [-1, 1] like our\n","    normalized input images.\n","    \"\"\"\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.main = nn.Sequential(\n","            # Input to convolution stage\n","            # intermediate state (ngf*8) x 4 x 4\n","            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf*8),\n","            nn.ReLU(True),\n","            # intermediate state (ngf*4) x 8 x 8\n","            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf*4),\n","            nn.ReLU(True),\n","            # intermediate state (ngf*2) x 16 x 16\n","            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf*2),\n","            nn.ReLU(True),\n","            # intermediate state ngff x 32 x 32\n","            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n","            nn.Tanh(),\n","            # output state 64 x 64\n","        )\n","\n","    def forward(self, inp):\n","        \"\"\"\n","        Feed input data forward to produce an output image\n","        \"\"\"\n","        return self.main(inp)\n","\n","\n","class Discriminator(nn.Module):\n","    \"\"\"\n","    helper class for the discriminator module\n","\n","    This operates similarly to the generator, except that now we are\n","    convolving with the current weights working toward a value judgement at\n","    the end.\n","    \"\"\"\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.main = nn.Sequential(\n","            # input size 64 x 64\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # intermediate state ndf x 32 x 32\n","            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf*2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # intermediate state (ndf*2) x 16 x 16\n","            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf*4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # intermediate state (ndf*4) x 8 x 8\n","            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf*8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # intermediate state (ndf*8) x 4 x 4\n","            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, inp):\n","        \"\"\"\n","        Feed input data forward to produce an output classification\n","        \"\"\"\n","        return self.main(inp)\n","\n","# Data marshalling helpers\n","dataset = dset.ImageFolder(root=dataroot,\n","    transform=transforms.Compose([\n","        transforms.Resize(image_size),\n","        transforms.CenterCrop(image_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n","    ]))\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n","shuffle=True, num_workers=2)\n","\n","# Check if GPU is available and set the device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Sanity check on dataset\n","real_batch = next(iter(dataloader))\n","plt.figure(figsize=(8,8))\n","plt.axis(\"off\")\n","plt.title(\"Training Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64],padding=2,\n","normalize=True).cpu(),(1,2,0)))\n","plt.show()\n","\n","# Set up networks\n","generator = Generator().to(device)\n","generator.apply(init_weights)\n","print(generator)\n","\n","discriminator = Discriminator().to(device)\n","discriminator.apply(init_weights)\n","print(discriminator)\n","\n","# Set up feedback optimizers\n","criterion = nn.BCELoss()\n","\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","real_label = 1\n","fake_label = 0\n","\n","optimizerD = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG= optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n","\n","\n","\n","\n","# Training loop with progress bar\n","img = []\n","G_loss = []\n","D_loss = []\n","iters = 0\n","\n","for epoch in range(num_epochs):\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n","\n","    # Create a progress bar for the batch loop\n","    pbar = tqdm(enumerate(dataloader, 0), total=len(dataloader), desc=\"Training Batches\", unit=\"batch\")\n","\n","    for i, data in pbar:\n","        # Train with known good data\n","\n","        # Zero out gradients\n","        discriminator.zero_grad()\n","\n","        # Prepare a batch\n","        real_cpu = data[0].to(device)\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","        # Feed forward\n","        output = discriminator(real_cpu).view(-1)\n","\n","        # Compute error and backpropagate\n","        errD_real = criterion(output, label)\n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        # Train with known fake data\n","        # Prepare a batch of random data for the latent space\n","        noise = torch.randn(b_size, nz, 1, 1, device=device)\n","\n","        # Generate batch of fake images\n","        fake = generator(noise)\n","        label.fill_(fake_label)\n","\n","        # Feed forward\n","        output = discriminator(fake.detach()).view(-1)\n","\n","        # Compute error and backpropagate\n","        errD_fake = criterion(output, label)\n","        errD_fake.backward()\n","        D_G_z1 = output.mean().item()\n","\n","        errD = errD_real + errD_fake\n","\n","        optimizerD.step()\n","\n","        # Train Generator\n","        # Prepare a batch of random data for the latent space\n","        noise = torch.randn(b_size, nz, 1, 1, device=device)\n","\n","        # Generate batch of fake images\n","        fake = generator(noise)\n","\n","        # Zero out gradients\n","        generator.zero_grad()\n","\n","        label.fill_(real_label)\n","\n","        # Get feedback from discriminator\n","        output = discriminator(fake).view(-1)\n","\n","        # Compute error and backpropagate\n","        errG = criterion(output, label)\n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","\n","        optimizerG.step()\n","\n","        # Update progress bar description\n","        pbar.set_postfix({\n","            \"Loss_D\": f\"{errD.item():.4f}\",\n","            \"Loss_G\": f\"{errG.item():.4f}\",\n","            \"D(x)\": f\"{D_x:.4f}\",\n","            \"D(G(z))\": f\"{D_G_z1:.4f}/{D_G_z2:.4f}\"\n","        })\n","\n","        # Save losses for plotting later\n","        G_loss.append(errG.item())\n","        D_loss.append(errD.item())\n","\n","        if (iters % 10 == 0) or ((epoch == num_epochs - 1) and (i == len(dataloader) - 1)):\n","            with torch.no_grad():\n","                fake = generator(fixed_noise).detach().cpu()\n","            img.append(vutils.make_grid(fake, padding=2, normalize=True))\n","            im_tens = fake[0]\n","            vutils.save_image(im_tens, f\"gen_{iters}.bmp\")\n","\n","        iters += 1\n","\n","# plot loss over time\n","plt.figure(figsize=(10,5))\n","plt.title(\"Generator and Discriminator Loss\")\n","plt.plot(G_loss, label='G')\n","plt.plot(D_loss, label='D')\n","plt.xlabel('iterations')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.show()\n","\n","# animate images development in generator\n","#fig  = plt.figure(figsize=(8,8))\n","#plt.axis(\"off\")\n","#ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img]\n","#ani = animation.ArtistAnimation(fig, ims, interval=1000,repeat_delay=1000,blit=True)\n","#HTML(ani.to_jshtml())\n","\n","\n","# Grab a batch of real images from the dataloader\n","real_batch = next(iter(dataloader))\n","\n","# Plot the real images\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,2,1)\n","plt.axis(\"off\")\n","plt.title(\"Real Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n","\n","# Plot the fake images from the last epoch\n","plt.subplot(1,2,2)\n","plt.axis(\"off\")\n","plt.title(\"Fake Images\")\n","plt.imshow(np.transpose(img[-1],(1,2,0)))\n","plt.show()\n","\n","# save the optimizer and discriminator state for the demo\n","torch.save(\n","    {\n","        'discriminator_state_dict':discriminator.state_dict(),\n","        'optimizerD_state_dict':optimizerD.state_dict(),\n","        'generator_state_dict':generator.state_dict(),\n","        'optimizerG_state_dict':optimizerG.state_dict()\n","    },\n","    'networkStates.pyt'\n",")\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyOer6GMwxYqqUHz2MANoX2/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}